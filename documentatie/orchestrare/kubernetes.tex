\subsection{General}

Containerele au reprezentat o soluție pentru problema comună privind modul de rulare și
lansare pe diverse mașini diferite ale căror sisteme, dependințe, versiuni de rulare și 
librării pot fi diferite (frecventa „But it works on my machine”), astfe un dezvoltator poate să
construiască și să lucreze la aplicație, acesta fiind atent să creeze imaginea, imediat după
un tester nu e nevoit să interacționeze direct cu sursa ci exclusiv cu imaginea, putând să 
verifice că nu a apărut nicio problemă și pe mașinile de build să ruleze testele automate direct pe imagine.
Ulterior, dacă imaginea reprezintă ceva ce trimitem în piață poate fi trimisă către operatori și
planificat pentru lansare.

Utilitatea Docker-ului și a containerelor fără nimic suplimentar s-ar termina totuși în acest punct.
Chiar dacă un operator nu ar trebui să instaleze dependințele aplicațiilor în fiecare loc unde ar rula,
acesta fiind înlocuit cu instalarea runtime-ului de Docker, acesta trebuie să se preocupe 
cu dificultățile lansării, adică unde este lansat, în cât timp, replicare, dacă sistemele
sunt în stare bună și alte detalii ce pot oglindii starea sistemului.

În acest scop, Docker nu ajută, la fel și itemii de care am discutat la simpla orchestrare a containerelor,
fiind o soluție în regulă pentru sisteme mici, atunci când vorbim la scală avem nevoie de unelte diferite.
Aici continuam folosind Kubernetes, o unealtă ce a apărut în 2014 devenită open-source 
care are ca scop orchestrarea unui cluster pe care rulează sub diferite forme și organizate
în moduri diferite containere

În dezvoltarea și crearea modului de interacționare folosind Kubernetes au fost folosite experiențele 
dobândite prin lucrul manual cu acestea, astfel s-a urmărit diferite puncte ce 
contribuie la avantajele în folosirea acestei tehnologii, incluzând creșterea vitezii de deployment
prin crearea unor sisteme imutabile bazate pe stări și nu pe modificări punctuale asupra sistemului
activ (configurare declarativă), prin crearea capacității de auto-reglare creat pornind
de la acest mod de configurare, astfel Kubernetes la cel mai simplu nivel, 
va aserta starea curentă și va încerca să o aducă la starea pe care este configurat să o aibă

În același timp, Kubernetes permite abstractizarea infrastructurii, astfel nu mai este 
necesar să cunoaștem mașinile virtuale sau sistemele ce rulează în interiorul clusterului,
suntem interesați doar de modul de interacționare cu clusterul, astfel creăm aplicații
care să ruleze pe acesta cu anumite configurări. Astfel, Kubernetes poate să mențină
mașinile virtuale mai încărcate întrucât acesta va încerca să eficientizeze consumul de resurse.

Soluțiile de lansare ce includ Kubernetes ne permit să fim foarte flexibili în modul
cum interacționăm cu acesta, și avem multe oportunități de rulare, însă „prețul”
plătit pentru toate opțiuniile pe care le avem este o creștere foarte mare 
de dificultate în crearea șo administrarea unui astfel de cluster, însă 
recent această dificultate poate fi eliminată prin folosirea de infrastructură 
în cloud precum Azure ce oferă Kubernetes as a Service, astfel administrarea clusterului
nu mai este o problemă ci doar creăm resursele de care avem nevoie.

\subsection{Obiecte de bază}

Atunci când folosim Kubernetes, deși putem folosi și comenzi manuale, ar trebui să 
abordăm o modalitate de gândire delcarativă. Kubernetes folosește obiecte la diferite 
nivele ce administrează obiecte la nivel inferior pentru a-și obține starea pe care 
este setat să o păstreze. Toate acestea se fac prin intermediul unor fișisere, 
în general de format YAML în care stabilim lucrurile de care avem nevoie. 

\subsubsection{Etichete și adnotări}

Întrucât administrarea unui cluster Kubernetes include administrarea de foarte multe obiecte,
fiecaruia dintre acestea pot să îi se adauge etichete ce sunt o pereche cheie-valoare,
în format de String-uri. După aplicarea unei etichete atunci asupra obiectului,
acestea se pot vedea atunci când inspectăm elementul. Aplicarea unei etichete se poate face
atunci când creăm un obiect, prin adăugarea lor asupra comenzi run,\\ \verb|kubectl run ... --labels="ver=1"|
sau separata folosind \verb|kubectl label [selector] "ver=1"|. O dată aplicat un label, 
acesta poate fi folosit pentru a selecta resursele cu acel label în cadrul altor comenzi 
precum cele de inspectare sau stergere \verb|kubectl get pods --selector "ver=1"| iar 
multiple etichete pot fi combinate cu operatii logice, \verb|kubectl get pods -l 'ver=1,canary'| ->
Pods-urile cu label-ul versiunii 1 si care au definit label-ul canary. Etichetele pot fi aplicate și de către alte obiecte 
pentru a identifica resursele pe care acestea le au în administrare. De exemplu, un ReplicaSet va aplica
etichete specificie asupra pod-urilor pe care acestea le administrează pentru a cunoaște ce schimbări
ar trebui să facă.

Întrucât etichetele au rol în modul de administrare al cluster-ului, adnotările au ca rol
adăugarea de metadata asupra unui obiect, sub forma tot de o pereche cheie-valoare ce pot 
folosi caractere mai variate ca etichetele. Aceasta poate fi preluate de alte librării
încercând să le oferim diferite informații precum versiunea sau să îmbunătățim 
vizibilitatea în cadrul unei interfețe de aministrarea a cluster-ului. 

\subsubsection{Pods}

Elementele Kubernetes pornesc de la Pods, acestea reprezintă corespondentul unui container
din lumea Docker, însă extins, astfel dacă vrem să rulăm un container în Kubernetes trebuie 
să folosim un pod.

Reprezintă o colecție de containere ce rulează împreună, astfel acestea partajează
metodele de acces (IP-uri, hostname-uri), astfel este garantat că rulează în interiorul
aceluiași nod, putând să comunice local prin metode de comunicare interproces, însă
două pod-uri identice pot să ajungă să ruleze pe noduri diferite prin replicare.

Reprezentând o colecție de containere, în interiorul unui pod ar trebui să 
avem programe ce comunică des împreună și care au nevoie să beneficieze de avantajele rulării
în acelaș mediu, de exemplu un server și o metodă de sincronizare cu un sistem central.

Crearea unui pod se poate face imperativ prin folosirea comenzii \verb|run|,
astfel putem crea un pod cu diferite proprietăți
pe care obișnuiam să le specificăm și la containere
\verb|kubectl run NAME --image=image|. Însă modul de creare recomandat 
pentru pod-uri este prin intermediul unor fișiere manifest, cel mai popular fiind scrise in YAML.
Rulând comanda de aplicare a modificarilor \verb|kubectl apply -f pod.yaml|, considerând
că în fișierul indicat avem un template pentru un pod și este valid, acesta va fi 
rulat pe un nod din cadrul clusterului Kubernetes pe care îl administrăm.

Pentru a vizualiza detalii despre pod-urile în executie folosim comenzi precum\\
\verb|kubectl get pods| ce ne dă o listă de pod-uri și detalii succinte despre acestea
și\\ \verb|kubectl describe pods NAME| unde primim mai multe detalii despre pod însă nu 
neapărat complet. Pentru a șterge un pod putem folosi comanda \verb|kubectl delete pods/NAME| sau
prin fișierul de configurare \verb|kubectl delete -f pod.yaml| iar după acesta, după o anumită
perioadă pod-ul va fi șters după o perioadă de grație.

O dată creat, serviciile dintr-un pod pot fi accesate direct prin intermediul\\
comenzii \verb|kubectl port-forward NAME port:port|, însă aceasta reprezintă o
metodă simplistă de accesare și nu poate fi recomandată. Pentru a prelua fișiere 
de logare din pod putem folosi comanda \verb|kubectl logs NAME|, pentru a rula comenzi în 
interiorul unui pod folosim \verb|kubectl exec -it NAME bash| și de asemenea putem copia fișiere
prin \verb|kubectl cp <pod-name>:/fisier ./fisier.txt|.

Pentru a facilita elementele de un nivel mai înalt, pod-urile trebuie să aibă 
definite o comandă ce indică starea acestora, de exemplu dacă un server web este activ. Astfel,
clusterul Kubernetes sau responsabilul acelui pod vor rula acele comenzi pentru a afla statusul 
pod-ului, dacă acesta nu este pozitiv atunci pod-ul poate să fie recreat. În același fel,
putem defini o comandă ce indică dacă un pod a fost pornit corespunzător și poate servi trafic, 
un readiness check, ce sunt create asemănător unui healthines check.

Prin fișierul de configurare al unui pod putem specifica un set de resurse minime și maxime pe care
un pod le poate avea, astfel putem să ne asigurăm că clusterul va rula pod-ul într-un mod eficient și
în același stil ca la containere stocarea pod-urilor nu este persistentă, astfel la fiecare rulare
datele pe care le avem pe acel pod sunt scrict cele de pe imagine și nu cele ale unor rulări anterioare.
Pentru a adăuga această caracteristică folosim volume ce sunt indicate în fișierul de template.

\subsubsection{Services}

Elementele administrate de Kubernetes pot apărea și dispărea în orice moment, fie datorită
unor scalări sau restrângeri de pods-uri în funcție de traficul care se desfășoară în cluster.
Din acest motiv, dacă avem replici a unor mai multe pods-uri, accesarea acestora devine dificilă 
atunci când punem in context scalarea. Pe Internet folosim DNS pentru a avea acces la 
servere fără a memora adrese IP exacte ce oricum se pot schimba, însă în Kubernetes
aceasta activitate este chiar și mai dinamică. Din acest motiv, nu putem folosi 
un DNS tradițional întrucât acesta poate cacha elementele mult mai mult decât ne dorim.

În Kubernetes putem crea servicii, astfel atunci când creăm niște pods ce rulează pe un port
putem crea un serviciu pentru acel port, astfel nativ vom avea un singur IP si un port
pe care alte pod-uri le pot folosi pentru a accesa asemănător unui DNS.

Însă acest trafic poate fi creat doar din cluster, pentru a permite elemente din afara 
pentru a accesa serviciul și implicit serviciul putem folosi NodePort în fișierul de 
configurare iar Kubernetes ne va oferi un IP prin care putem accesa serviciul.

\subsubsection{Ingress}

Definirea serviciilor se bazează doar pe IP și pe un port, astfel el rulează la 
Layer 4, din acest motiv nu putem să creăm redirecționare bazată pe ce conține 
calea căutate.

Pentru a rezolva acestă lipsă, putem adăuga un layer suplimentar care pentru 
aplicațiile ce se bazează pe HTTP poate funcția ca și load balancer sau ca reverse proxy
și în Kubernetes au numele de Ingress.

Deși avem acces la obiectul de tip Ingress direct din Kubernetes, 
nu există implementarea acestuia astfel aceasta trebuie să fie adăugată ca separat,
însă modalitățile de configurare și diferitele fișiere de care am avea nevoie pentru
a configura din punct de vedere Kubernetes sunt standardizate.

După ce configurăm Ingress-ul, vom putea avea acces la mai multe servicii din cadrul
clusterului și vom putea să redirecționăm către acestea prin intermediul controllerului
în funcție de configurările noastre, de exemplu după hostname sau căi și să rescriem
căile de acces sau să folosim TLS.

\subsubsection{Replica Sets}

Am observat că există multe avantaje pe care le putem avea rulând același server
de mai multe ori creând redundanță, astfel dacă un nod ar fi afectat ar exista un alt nod
deja pregătit pentru a servi trafic. În același timp putem face ca acest nod 
să fie mai apropiat de anumiți clienți în funcție de zona serverului și în același mod
folosind metodele de rutare din Ingress să partajăm traficul în funcție de conținutul
pe care vrem să îl servim (sharding).

Modalitatea principală de a interacționa Kubernetes este declarativ stabilind 
o anumită stare ideală pe care vrem ca sistemul să o aibă, astfel acesta s-ar ocupa
de a menține această stare, fie prin crearea mai multor resurse pentru a ajunge la 
acea stare inițială sau să scadă din resursele deja create.

În acest mod de operare, Replica Sets reprezintă fix acest lucru, acesta funcționează 
la un nivel mai înalt de Pod-uri, astfel specificând numărul de replici pe care ni-l dorim
din template-ul unui specific Pod, Replica Set-ul va avea responsabilitatea de a menține
acel număr. Pentru a face asta, el va aplica anumite etichete astfel va cunoaște 
asupra căror Pod-uri poate să actționeze.

Crearea de Replica Sets se face creând un fișier de configurare specific și aplicat folosind
comanda \verb|kubectl apply -f NAME.yaml|

\subsubsection{Deployments}

O altă problemă frecvent apărută este modalitatea de aducere a modificărilor în piață.
Atunci când avem un server sau o colecție de servere pornite atunci când vrem 
să adăugăm anumite schimbări asupra funcționalităților oferite inevitabil vom avea
un timp în care nu vom putea servi clienți, o perioadă necesară de mentenanță, în 
același fel putem întâlnii problema în care există două servere în același timp ce
ar face același lucru însă datorită existenței a două versiuni diferite, practic
clienții pot apela oricare dintre versiuni.

Pentru a rezolva aceste probleme în Kubernetes avem obiectul de Deployements
ce are ca rol să administreze un set de Replica Sets și poate să aducă actualizări 
în diferite moduri, recrearea tuturor pod-urile curente prin strategia de Recreate,
aceasta crează o perioadă de down-time și prin RollingUpdate în care pod-urile sunt
create pas cu pas, iar numărul de câte pod-uri necesare să fie disponibile sau alți 
parametrii pot fi configurate. Kubernetes face asta schimbând parametrii obiectelor
de Replica Sets pe care acesta le crează și terminând activitatea pod-urilor pe care 
acestea le au în supervizare.

Pentru a păstra stabilitatea sistemului, la fel ca în cazul Replica Sets, se vor
urmării parametrii de healthiness și se vor aștepta ca acestea să fie ready și 
healthy.

\subsubsection{DaemonSets}

Atunci când configurăm un Deployment o facem pentru a avea un număr specific de 
replici ale unui serviciu, scalate în funcție de setări și ar fi preferabil 
ca poziționarea acestora să fie pe cât mai multe moduri distincte.

Însă existând necesitatea de a avea nevoie să avem servicii care rulează pe toate
nodurile pe care le avem apare conceptul de DaemonSets, acestea au ca scop rularea unui container
pe toate nodurile însă funcționalitatea acestuia are strict legătură cu rularea o singură dată pe acel nod
iar replicarea acestuia nu ar aduce vreun beneficiu.

Crearea unui astfel de obiect se face tot prin intermediul unui fișier de configurare 
pe care îl aplicăm folosind comanda \verb|apply|, și putem specifica anumite etichete 
pentru a specifica doar anumite noduri pe care vrem să ruleze serviciul.

\subsubsection{Jobs}
