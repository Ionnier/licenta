Ciclul de viață al unei aplicații monolitice continuă să fie simplă și în contextul
lansării acesteia. În urma trecerii prin toate fazele pipe-ului de build și posibila
validare manuală acesta poate fi trimis către client sau urcat din diverse platforme
de hostare, posibil să existe o perioadă în care platforma nu ar putea să fie accesibilă
datorită necesității de a reporni, dacă nu folosim un proces mai amplu de lansare 
care ar acoperi aceste goluri. Dacă este implicată și o bază de date atunci aceasta poate 
să fie lansate înaintea aplicației și totul ar funcționa, dacă este invers atunci probabil
aplicația tratează cazurile în care aceasta nu este disponibilă.

În cazul microserviciilor, procesul este mai complex întrucât caracteristica specficiă 
acestora este capacitatea de a fi lansate și a funcționa independent de celelalte, chiar
dacă pot fi uneori limitate de absența celorlalte, astfel procesul menționat anterior 
se repetă pentru fiecare microserviciu. Totuși, fiecare microserviciu poate să fie de o tehnologie
diferită, poate ca baza de date a fiecăruia să aibă un anumit tip și anumite cerințe de lansare,
astfel flexibilitatea oferită de acestea se poate resimți atunci când este timpul lansării.

Până acum, toate conexiunile între microservicii erau făcute doar logic, nu cunoșteam 
detalii despre modul cum acestea vor fi aranjate sau unde vor fi lansate sau sub ce formă.
O caracteristică a microserviciilor este capacitatea de a scala un anumit serviciu ce simte
o cerere mai mare, în acest context putem avea mai multe instanțe al aceluiași microserviciu,
la fel cum am face și cu o aplicație monolitică în cazul în care am vrea să servim mai mulți
clienți, mai lansăm o copie a aplicației. În acest caz, comunicarea nu se va mai putea 
face direct către microservicii întrucât scalarea se face automat, ci este nevoie să comunicăm
cu un intermediar ce ar face rutarea către acestea care are și scop să echilibreze
traficul între cele două, astfel folosim un load balancer și vom comunica direct cu acesta 
și nu cu microserviciul propriu-zis. În cazul comunicării cu evenimente, trebuie doar să 
ne asigurăm că evenimentul este consumat de un singur microserviciu iar în urma se va 
lansa evenimentul răspuns.

Un factor important însă care a fost ignorat în lansarea microserviciilor, este baza de date.
Întrucât fiecare microserviciu trebuie să aibă propria bază de date pentru a-și ascunde starea
internă și să poată să aibă control asupra tuturor operațiilor ce ar avea loc pe 
domeniul său, microserviciul trebuie să fie lansat împreună cu aceasta independent. Însă 
în momentul în care avem mai multe microservicii de același tip, adică mai multe replici,
baza de date va fi defapt comună pentru toate microserviciile, adică toate replicile
vor folosi ca sursă de date același loc. În acest context apar probleme cu scalarea,
întrucât e posibil ca serviciul nostru să scaleze infinit, baza de date nu se va scala, 
astfel poate să devină un impediment în performanța sistemului, dacă nu cumva își cauzează
sieși atacuri de tipul Denial of Service prin existența prea multor cereri. Însă scalarea
bazelor de date este complicată, mai ales în cazul în care acestea sunt relaționale, întrucât
necesită fragmentarea datelor ceea ce este greu de calculat, din acest motiv putem 
construi organizări precum existența unei singure baze de date pentru scriere și multiple
baze de date pentru citire, în acest context putem separa traficul însă datele pe care le 
servim pot să nu fie actualizate. Modul de lansare al bazei de date poate să difere de cel
al microserviciilor, mai ales pentru companiile existente ce au deja date, migrarea devine
mult mai dificilă, din acest motiv aceștia pot preferă să folosească infrastructura existentă
în loc să migreze către cloud unde ar putea avea o bază de date per microserficiu, astfel microserviciile
pot avea baze de date logic diferite însă care rulează de pe aceleași server.

Atunci când se rulează un microserviu se crează un mediu lucru pentru acesta. Când acesta
este în dezvoltare, programatorul are drepturi depline la locul în care acesta rulează și
cu ce alte microservicii comunică, însă atunci când ajunge în producție microserviciul are
alt mediu ceea ce face creșterea importanței creării unui mediu de testare cât mai asemănător
cu cel pe care va rula. Un exemplu simplu sunt datele de test, întrucât acestea pot avea
o anumită distribuție atunci când sunt în producție și alta atunci când generăm aleator
date, din acest motiv timpul de răspuns al bazei de date și alegerea parametrilor de
indexare nu poate fi ușor testată fără să interacționăm direct cu mediul de producție,
iar existența anumitor legi nu ne permite să copiem datele utilizatorilor în mediul de test
cu ușurință. Astfel lansarea microserviciului trebuie să fie ușor de adaptat pentru fiecare mediu,
fie el prin anumite variabile ce ar lua valorile mediului sau comportamente diferite în funcție
de numărul de instanțe ale microserviciului în fiecare loc.

Lansarea și mentenanța microserviciilor este o sarcină ce necesită coordonarea mai multor echipe, 
în general cei care se ocupă cu dezvoltarea nu o să se implice în configurarea infrastructurii, 
din acest motiv există câteva principii pe care le putem urmării atunci când lucrăm cu microservicii
pentru a maximiza caracteristicile pe care acestea le oferă.

Întrucât microserviciile sunt implementate pentru a rula independent, ar fi o idee bună ca acestea
să ruleze independent. În general, dificultățile în crearea infrastructurii apar atunci când
sistemele de calcul trebuie să fie configurate, astfel o metodă ar fi lansarea microserviciilor
pe aceași mașină, în acest caz monitorizarea sistemului scade întrucât metricile asupra
impactului peste componente nu ar putea fi atribuit unui anumit microserviciu, în același stil
acestea nu ar putea să fie la fel de scalabile și ar fi constrânse la fel ca o aplicație monolitică.
Recent, acesta a devenit mai ușor prin lansarea în container sau prin platforme precum Heroku
ce izolează sistemele by default. Există mai multe tipuri de izolare în funcție de modul în care lansăm
aplicația din acest motiv, cu cât izolarea este mai puternică cu atât cresc costurile asociate
acelui microserviciu și dificultățile în administrare.

Toate activitățile încep manual însă în timp ce le facem putem să găsim metode de a le eficientiza,
în general prin automatizare. Atunci când încercăm o arhitectură bazată pe microservicii, 
crește complexitatea lansării, astfel unele configurări care într-o aplicație monolitică 
era ușor de considerat că nu merită să se încerce să se automatizeze, în microservicii ar trebui
ca tot ce se poate automatiza să fie automatizat. În general, problemele care apar pot să fie 
din greșeli umane care nu pot să fie evitate. Putem porni procesul de încercare a automatizării
prin adaptarea de tehnologii și procese ce ne pot ajuta în acest scop.

Dezvoltarea cu ajutorul Git-ului ne permite să observăm schimbările din cod foarte ușor, 
putem să avem un istoric și persoanele implicate iar atunci când se crează o schimbare
prin intermediul Pull Request-urilor putem fi anunțați că se dorește modificarea unei porțiuni de cod.
În domeniul configurării infrastructuri aceasta se face manual, prin aducerea infrastructurii prin
instalarea de computere, crearea unor mașini virtuale sau rularea unui container. Toate acestea
implică munca unui operator ce ar trebui să seteze mașinile și ulterior să le configureze prin intrarea
manuală prin SSH, comenzile făcute în interior, deși înregistrare nu sunt la fel de ușor
vizibile ca și ceva pe Git, astfel a apărut conceptul de infrastructură ca și cod în care
infrastructura este configurată prin intermediul unor limbaje ce pot fi interpretate de 
unelte ce vor configura pentru noi computerele precum Puppet sau Ansible. Acestea ajută să
scriem starea mașinii într-un mod declarativ iar acestea vor rula script-urile de care avem nevoie
în interior. Terraform este o unealtă ce ajută în crearea resurselor ce provin din platforme cloud
precum Azure sau AWS. Având infrastrctură ca și cod aceasta poate fi urmarită de toți participanți și 
în același timp poate fi reaplicată pentru toate resursele ce trebuie să fie configurate în același
stil.

