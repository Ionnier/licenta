Ciclul de viață al unei aplicații monolitice continuă să fie simplă și în contextul
lansării acesteia. În urma trecerii prin toate fazele pipe-ului de build și posibila
validare manuală acesta poate fi trimis către client sau urcat din diverse platforme
de hostare, posibil să existe o perioadă în care platforma nu ar putea să fie accesibilă
datorită necesității de a reporni, dacă nu folosim un proces mai amplu de lansare 
care ar acoperi aceste goluri. Dacă este implicată și o bază de date atunci aceasta poate 
să fie lansate înaintea aplicației și totul ar funcționa, dacă este invers atunci probabil
aplicația tratează cazurile în care aceasta nu este disponibilă.

În cazul microserviciilor, procesul este mai complex întrucât caracteristica specficiă 
acestora este capacitatea de a fi lansate și a funcționa independent de celelalte, chiar
dacă pot fi uneori limitate de absența celorlalte, astfel procesul menționat anterior 
se repetă pentru fiecare microserviciu. Totuși, fiecare microserviciu poate să fie de o tehnologie
diferită, poate ca baza de date a fiecăruia să aibă un anumit tip și anumite cerințe de lansare,
astfel flexibilitatea oferită de acestea se poate resimți atunci când este timpul lansării.

Până acum, toate conexiunile între microservicii erau făcute doar logic, nu cunoșteam 
detalii despre modul cum acestea vor fi aranjate sau unde vor fi lansate sau sub ce formă.
O caracteristică a microserviciilor este capacitatea de a scala un anumit serviciu ce simte
o cerere mai mare, în acest context putem avea mai multe instanțe al aceluiași microserviciu,
la fel cum am face și cu o aplicație monolitică în cazul în care am vrea să servim mai mulți
clienți, mai lansăm o copie a aplicației. În acest caz, comunicarea nu se va mai putea 
face direct către microservicii întrucât scalarea se face automat, ci este nevoie să comunicăm
cu un intermediar ce ar face rutarea către acestea care are și scop să echilibreze
traficul între cele două, astfel folosim un load balancer și vom comunica direct cu acesta 
și nu cu microserviciul propriu-zis. În cazul comunicării cu evenimente, trebuie doar să 
ne asigurăm că evenimentul este consumat de un singur microserviciu iar în urma se va 
lansa evenimentul răspuns.

Un factor important însă care a fost ignorat în lansarea microserviciilor, este baza de date.
Întrucât fiecare microserviciu trebuie să aibă propria bază de date pentru a-și ascunde starea
internă și să poată să aibă control asupra tuturor operațiilor ce ar avea loc pe 
domeniul său, microserviciul trebuie să fie lansat împreună cu aceasta independent. Însă 
în momentul în care avem mai multe microservicii de același tip, adică mai multe replici,
baza de date va fi defapt comună pentru toate microserviciile, adică toate replicile
vor folosi ca sursă de date același loc. În acest context apar probleme cu scalarea,
întrucât e posibil ca serviciul nostru să scaleze infinit, baza de date nu se va scala, 
astfel poate să devină un impediment în performanța sistemului, dacă nu cumva își cauzează
sieși atacuri de tipul Denial of Service prin existența prea multor cereri. Însă scalarea
bazelor de date este complicată, mai ales în cazul în care acestea sunt relaționale, întrucât
necesită fragmentarea datelor ceea ce este greu de calculat, din acest motiv putem 
construi organizări precum existența unei singure baze de date pentru scriere și multiple
baze de date pentru citire, în acest context putem separa traficul însă datele pe care le 
servim pot să nu fie actualizate. Modul de lansare al bazei de date poate să difere de cel
al microserviciilor, mai ales pentru companiile existente ce au deja date, migrarea devine
mult mai dificilă, din acest motiv aceștia pot preferă să folosească infrastructura existentă
în loc să migreze către cloud unde ar putea avea o bază de date per microserficiu, astfel microserviciile
pot avea baze de date logic diferite însă care rulează de pe aceleași server.

Atunci când se rulează un microserviu se crează un mediu lucru pentru acesta. Când acesta
este în dezvoltare, programatorul are drepturi depline la locul în care acesta rulează și
cu ce alte microservicii comunică, însă atunci când ajunge în producție microserviciul are
alt mediu ceea ce face creșterea importanței creării unui mediu de testare cât mai asemănător
cu cel pe care va rula. Un exemplu simplu sunt datele de test, întrucât acestea pot avea
o anumită distribuție atunci când sunt în producție și alta atunci când generăm aleator
date, din acest motiv timpul de răspuns al bazei de date și alegerea parametrilor de
indexare nu poate fi ușor testată fără să interacționăm direct cu mediul de producție,
iar existența anumitor legi nu ne permite să copiem datele utilizatorilor în mediul de test
cu ușurință. Astfel lansarea microserviciului trebuie să fie ușor de adaptat pentru fiecare mediu,
fie el prin anumite variabile ce ar lua valorile mediului sau comportamente diferite în funcție
de numărul de instanțe ale microserviciului în fiecare loc.

Lansarea și mentenanța microserviciilor este o sarcină ce necesită coordonarea mai multor echipe, 
în general cei care se ocupă cu dezvoltarea nu o să se implice în configurarea infrastructurii, 
din acest motiv există câteva principii pe care le putem urmării atunci când lucrăm cu microservicii
pentru a maximiza caracteristicile pe care acestea le oferă.

Întrucât microserviciile sunt implementate pentru a rula independent, ar fi o idee bună ca acestea
să ruleze independent. În general, dificultățile în crearea infrastructurii apar atunci când
sistemele de calcul trebuie să fie configurate, astfel o metodă ar fi lansarea microserviciilor
pe aceași mașină, în acest caz monitorizarea sistemului scade întrucât metricile asupra
impactului peste componente nu ar putea fi atribuit unui anumit microserviciu, în același stil
acestea nu ar putea să fie la fel de scalabile și ar fi constrânse la fel ca o aplicație monolitică.
Recent, acesta a devenit mai ușor prin lansarea în container sau prin platforme precum Heroku
ce izolează sistemele by default. Există mai multe tipuri de izolare în funcție de modul în care lansăm
aplicația din acest motiv, cu cât izolarea este mai puternică cu atât cresc costurile asociate
acelui microserviciu și dificultățile în administrare.

Toate activitățile încep manual însă în timp ce le facem putem să găsim metode de a le eficientiza,
în general prin automatizare. Atunci când încercăm o arhitectură bazată pe microservicii, 
crește complexitatea lansării, astfel unele configurări care într-o aplicație monolitică 
era ușor de considerat că nu merită să se încerce să se automatizeze, în microservicii ar trebui
ca tot ce se poate automatiza să fie automatizat. În general, problemele care apar pot să fie 
din greșeli umane care nu pot să fie evitate. Putem porni procesul de încercare a automatizării
prin adaptarea de tehnologii și procese ce ne pot ajuta în acest scop.

Dezvoltarea cu ajutorul Git-ului ne permite să observăm schimbările din cod foarte ușor, 
putem să avem un istoric și persoanele implicate iar atunci când se crează o schimbare
prin intermediul Pull Request-urilor putem fi anunțați că se dorește modificarea unei porțiuni de cod.
În domeniul configurării infrastructuri aceasta se face manual, prin aducerea infrastructurii prin
instalarea de computere, crearea unor mașini virtuale sau rularea unui container. Toate acestea
implică munca unui operator ce ar trebui să seteze mașinile și ulterior să le configureze prin intrarea
manuală prin SSH, comenzile făcute în interior, deși înregistrare nu sunt la fel de ușor
vizibile ca și ceva pe Git, astfel a apărut conceptul de infrastructură ca și cod în care
infrastructura este configurată prin intermediul unor limbaje ce pot fi interpretate de 
unelte ce vor configura pentru noi computerele precum Puppet sau Ansible. Acestea ajută să
scriem starea mașinii într-un mod declarativ iar acestea vor rula script-urile de care avem nevoie
în interior. Terraform este o unealtă ce ajută în crearea resurselor ce provin din platforme cloud
precum Azure sau AWS. Având infrastrctură ca și cod aceasta poate fi urmarită de toți participanți și 
în același timp poate fi reaplicată pentru toate resursele ce trebuie să fie configurate în același
stil.

Funcționarea independentă ne permite să lansăm produse fără ca alte microservicii să necesite
o actualizare, în acest context putem să facem lansări mult mai dese accelerând dezvoltarea,
acestea aduc avantajul că putem face o lansare pentru un număr restrâns de caracteristici,
astfel dacă apar probleme în producție putem să fixăm mult mai ușor întrucât sunt puține
funcționalități schimbate. În acest context trebuie să măsurăm contextul în care 
sunt afectate celelalte microservicii atunci când facem o lansare, în mod tradițional
sistemul ar fi oprit și ar cauza o perturbare pentru consumatori și ulterior al utilizatorilor.
Această probleme poate fi diminuată cu tehnici de lansare precum lansarea treptată în care
serviciile existente se actualizează una câte una în timp ce consumatorii existenți sunt păstrați
iar cei noi redirecționați către cele noi. În cazul acesta apar probleme atunci când între 
microserviciu și client se crează conexiuni de lungă durată precum un socket întrucât acestea
nu pot fi întrerupte fără a cauza dificultăți.

O altă specificație importantă este capacitatea de a putea configura o stare dorită a întreg 
sistemului și să folosim uneltele potrivite pentru ca acesta să se întâmple. În acest
scenariu, platforma folosită va monitoriza sistemul și va aplica comenzile necesare pentru
a păstra forma dorită. Printre astfel de unelte se numără Kubernetes, iar unii distribuitori
de infrastructură în cloud oferă aceleși servicii. În acest context, întrucât platforma este 
cea care administrează starea este important să automatizăm modul de lansare, astfel platforma
primește doar imaginea și o aplică. O continuare al acestui mecanism este GitOps, la fel ca
infrsastructura ca și cod care prevedea configurarea sistemelor ca și cod, acest sistem
prevede menținerea stării ca și cod și folosirea unor operatori automați care vor aplica
comenzile din acel repository. Acest procedeu are aceleși beneficii ca și pentru infrastructură, 
adică capacitatea de a avea o privire mai bună per ansamblu, un istoric, anunțarea schimbărilor
și interogatoriu. În acest mod de lucru configurarea manuală a infrastructurii pe care 
rulează sistemul nu mai este permisă, iar fiecare schimbare se va face în repo.

Locurile în care putem să lansăm microserviciile vor fi mai detaliate în \autoref{orchestrare} % TODO: Maybe try to change this
însă la fel cum avem flexibilitate în implementare, avem flexibilitate și în lansare. Acestea 
pot include o lansare directă pe mașini direct sau într-o abstractizare precum un container sau ca
Function as a Service (FaaS), astfel ar trebui să ne documentăm despre opțiunile pe care le avem,
avantajele și dezavantajele fiecareia și ce suntem confortabili să facem pentru a administra sistemul.
Ar trebui să folosim metodele existente de deployment însă dacă acestea au nevoie de modernizare
atunci putem face schimbări. Cu ajutorul platformele existente precum FaaS sau containerizarea
aplicației putem să scădem dificultățile în configurarea mediului și să ne concentrăm doar pe
rulare. În același mod se pierde controlul asupra modului de configurare întrucât 
acesta va fi administrat de platformă, astfel dacă folosim servicii precum Heroku, acesta ne va oferi
anumiți parametrii însă configurarea efectivă a sistemului de calcul va fi abstractizată ceea ce ne
permite să ne concentrăm pe alte aspecte ale sistemului. 

În cadrul implementării unei lansări eficiente s-au adunat doi termeni, livrare continuă
(continuous delivery) și lansare continuă (continuos deployment). Diferența între cele două
se crează la starea produsului. Cea din urmă poate fi considerată chiar și o continuare.
Livrarea continuă se referă la menținerea produsului într-o stare în care poate fi lansat.
Lansarea continuă se referă la automatizarea procesului din care produsul livrabil ajunge
la utilizatori, astfel conceptul de intrare a unei caracteristici „în producție” poate fi considerat
schimbat, astfel această stare poate fi considerată atunci când aceasta intră în produsul livrabil,
deși ea nu a ajuns la consumatori. Lansarea continuă poate fi limitată de platformele pe care 
lucrăm dar și de modul de organizare, astfel acesta necesită crearea unei automatizări 
puternice atunci când dezvoltăm produsul.
