\subsection{Stabilitate}
Într-un proces clasic de dezvoltare a software-ului în stilul Waterfall, după ce aplicația
este construită, testată și trece de audit-ul echipei de securitate aceasta va fi lansată și
se va ajunge în starea de mentenanță. Însă modern, dezvoltarea aplicației nu se termină
aici ci se va dori extinderea, consumul aplicației de către diferite interfețe, scăderea
numărului de erori și tratarea acestora dar și eficientizarea sistemului.

Fiind implicată conexiunea prin Internet dar și globalizarea, utilizatorii se așteaptă
ca serviciile pe care le oferim să fie disponibile 24/7. O arhitectură distribuită ne
permite să creștem această disponibilitate întrucât poate să se întâmplă ca un serviciu
pe care îl creăm să fie căzut, celelalte fie nu ar fi afectatate sau ar rula într-o variantă
mai limitată.

Pentru a crește reziliența sistemului putem definii anumite arii în care aceasta acționează.
Când aplicația poate să trateze erori pe care le anticipăm, precum tratarea erorilor sau
reîncercarea cererilor căzute. Din această cauză putem să construim soluții ce devin mai complicate,
de exemplu adoptarea Kubernetes pentru a beneficia de facilitățile acestuia precum
menținerea constantă a stării, introducem complexitate și un efort ce poate să creeze mai multe
probleme. Capacitatea de a absorbi atunci când se produce o anomalitate sporește stabilitatea
sistemului, concentrarea pe îmbunătățirea metodelor de prevenire al cazurilor de acest
tip ne poate lăsă vulenaribili, astfel putem crea metode de recuperare sau metode alternative
de funcționare atunci când apar probleme în sistem. Creșterea rezilienței ar trebui să
fie făcută constant și să ne adaptăm la evoluția sistemului.

Deși putem încerca să reducem șansele de apariție ale unei probleme, acestea nu pot fi evitate,
iar acestea pot apărea la orice nivel al aplicației inclusiv în afara ei la partea de infrastructură.
Însă tratarea tuturor evenimentelor care ar apărea ar fi obositor și nu ar da randament,
întrucât pot fi microservicii în sistemul nostru la care ne putem aștepta să cadă și să
nu creeze perturbări la fel de mari. Astfel putem să testăm monitorizăm sistemul și
să calculăm timpi de răspuns, dacă aceștia nu sunt în parametrii pe care îi dorim
putem folosi sisteme de scalare, sau a timpului în care sistemul este căzut și stabilirea
dacă aceasta este acceptabilă la fel și cât de multe date putem să pierdem.

Pentru a continua funcționalitatea sistemului în procent cât mai mare, uneori e nevoie
să facem compromisuri, astfel dacă cunoaștem că un microserviciu de care suntem
dependenți este căzut, putem să îl ascundem, astfel utilizatorul are o experiență mai proastă,
însă sistemul încă este disponibil. Metode de menținere a stabilității sistemului pentru
astfel de situații pot fi, introducerea de time-out-uri în cereri, astfel clienții nu așteaptă
mai mult decât trebuie. Durata după care se introduce un timeout poate fi calculată
după rularea testelor și adjustată conform telemetriei. Însă unele erori pot să fie
doar temporare, iar o reîncercare probabil ar fixa problema, în acest caz putem
introduce un sistem de reîncercare în funcție de eroare pe care o primim. Aceste două metode
de tratare a eșecului totuși sunt costisitoare din punctul de vedere al timpului. Întrucât
conexiunile încete și un număr ridicat de reîncercări ar face ca clientul să trebuiască
să aștepte foarte mult, chiar și pentru o eroare. În acest caz putem crea un fel de siguranță
ce are scopul ca atunci când avem funcționalitatea normală aceasta să continue, iar atunci
când avem probleme în sistem, clienții care ar încerca să acceseze resursele afectate ar primi
un răspuns cât mai rapid, astfel nu ar cauza frustrări pentru aceștia. Erorile se pot
propaga, astfel crearea unei izolări între microservicii ar cauza ca acestea își afectează
starea reciproc. În acest sens putem crea separări logice în care comunicare între microservicii
se face printr-un intermediar care în absența unuia dintre participanți va salva lucrurile
ce trebuie să le trimită și le va trimite atunci când va fi disponibil, sau izolare
fizică, astfel să ne asigurăm că bazele de date ale microserviciilor dar și aplicațiile în sine
sunt separate între ele, astfel dacă un server cade, nu ar afecta mai multe servicii în același timp.
Deși acest lucru este mai costisitor putem să folosim asta și să coordonăm metodele
de eșec, astfel dacă știm că funcționalitate unui serviciu este puternic afectată
de un altul, atunci acestea pot fi grupate și dacă inevitabilul se întâmplă cele două
vor cădea împreună. În același stil putem să creștem numărul de apariții ale unui microserviciu,
astfel dacă unul din ele este căzut, avem alte clone ce îi pot lua locul. Platforme precum
Kubernetes ne permite să facem acest lucru cu ușurință. În același stil, putem să trimitem
mai multe cereri de mai multe ori, acest lucru funcționează dacă cererile create și modul
lor de prelucrare este idempotent, adică de oricât de multe ori este aplicat, acesta
va da mereu același rezultat oricât de multe rulări am face.

În construirea unui sistem bazat pe microservicii stabil am discutat despre metode de
eficientizare și de îmbunătățire a rezilienței în care folosim mai multe baze de date sau
multiple instanțe ale unui microserviciu. Există o teoremă ce a fost demonstrată și matematic ce
spune că putem avea consistență, disponibilitate (avalability) și tolerare a separărilor
(partition tolerance) însă dintre acestea putem să alegem în sistemul nostru doar două dintre ele,
a treia neputând fi atinsă. Consistența reprezintă ca oricare din instanțele ale unui microserviciu,
toate ar oferi același răspuns pentru aceași cerere. Disponibilitatea reprezintă capacitatea
unui microserviciu de a primi un răspuns iar toleranța separării reprezintă capacitatea
sistemului de a manevra incapacitatea serviciilor de a comunica între ele.

Renunțând la consistență ar însemna ca atunci când avem mai multe microservicii de același tip ce comunică
cu o bază de dată, dacă nimerim la noduri diferite am primi răspuns diferit. Acest lucru se
poate întâmpla atunci când baza de date este formată din mai multe baze de date, unele
destinate doar citirii iar una doar pentru scriere. În acest context, sincronizarea
dintre cele două tipuri de baze de date este pe moment întreruptă. În general putem
sacrifica un pic din consistență în funcție de importanța datelor cu care lucrăm, însă
ne așteptăm ca sincornizarea să se facă la un moment dat, cu cât aceasta întârzie cu atât
va fi mai dificil de executat, iar dacă refuzăm scrieri atunci când sincronizarea
este lentă o să menținem consistența ridicată dar disponibilitatea scăzută.

Consistența este greu de atins întrucât necesită mulți pași pentru menținerea ei, iar interogarea
datelor se face inițiind tranzacții pentru a ne asigura că datele pe care vrem să
le accesăm sunt cu adevărat la fel, iar dacă aceste noduri nu sunt disponibile, atunci pentru a
nu sacrifica consistența vom refuza cererea, astfel scăzând disponibilitatea. Crearea unui mod
de partajare a datelor între mai multe noduri este dificilă, astfel ar fi bine să folosim
soluții deja implementate, Consul oferă astfel de servicii pentru disitribuirea elementelor
de configurare.

Negarea tolerării separări este imposibilă în cadrul unui sistem distribuit, întrucât aceasta
ar însemna să renunțăm la microservicii și să revenim la o arhitectură monoliticăm în care
nu există separare. Astfel singurele tipuri de sisteme pot fi CP sau AP, adică cele care
renunță la disponibilitate, respectiv la consistență, însă în lumea reală acesta nu
este neapărat aplicabil. Putem în cadrul unui singur sistem să avem mai multe tipuri de alegeri,
în funcție de datele și tehnologia cu care lucrăm.

Testarea stabilității unui sistem distribuit este destul de complicat și s-ar face la mai multe nivele.
Un termen popular, original provenit de la Netflix, este „chaos engineering” (ingineria haousului)
acesta are ca rol testarea rezilienței sistemului. În general, poate fi considerat
ca doar rularea unor unor unelte și interpretarea acestora, ceea ce nu e greșit, însă
aceasta are ca scop îmbunătățirea încrederii atunci când apar probleme ce nu pot fi
prevăzute, ceea ce se poate întâmpla în orice moment. Netflix se bazează într-o proporție
foarte mare de infrastructura ce provine de la AWS, însă la un moment dat aceștia au fost
forțați să efectueze lucrări de mentenanță asupra unei întregi zone de serviciu, astfel
se putea crea o gaură mare de down-time pentru clienții Netflix (dar și pentru ceilalți ce se
bazează pe AWS). Ei au creat un serviciu numit Chaos Monkey ce are ca scop testarea sistemului
la apariția unor probleme neprevăzute în cadrul infrastructurii. În cadrul serviciului
putem întâlnii mai multe stagii precum, Chaos Gorilla ce are ca scop căderea unei zone de disponibilitate,
adică a unei regiuni mai mici (Europe Central), Chaos Kong, simulează căderea unei regiuni întregi,
de exemplu Europa, Latency Monkey are ca scop creșterea latenței în cererile executate
de clienți pentru a simula încetiniri în trafic, Conformity Monkey are ca scop
închiderea instanțelor ce nu sunt în conformitate cu practicile cerute de sistem,
Doctor Monkey monitorizează starea fiecărei instanțe și oprește sistemele ce nu sunt tratate în timp util,
Janitor Monkey observă infrastructura ce nu este utilizată și o oprește după un anumit timp,
Security Monkey are ca scop închiderea serverelor ce nu au toate practicile de securitate
necesare.

\subsection{Scalare}

În timpul prezentării microserviciilor, un avantaj al acestora a fost mereu flexibilitatea,
în același stil am menționat posibilitatea îmbunătățirii sistemului prin replicarea unor
anumite funcții ale acestuia, fie pentru administrarea a mai mult trafic, fie pentru
îmbunătățirea disponibilității și eliminarea timpilor în care serviciul este inaccesibil.
Scalarea poate fi făcută în mai multe moduri, în funcție de necesitățile și de problemele
pe care le-am rezolva.

Scalarea verticală se referă la îmbunătățirea sistemului de calcul
prin aducerea mai multor resurse de calcul, fie prin îmbunătățirea sistemelor de I/O,
adică folosirea unor SSD-uri rapide față de HDD-uri clasice, fie de calcul prin
îmbunătățirea procesorului și a memoriei RAM. În cazurile clasice, când noi suntem
cei care hostăm aplicația, aceasta poate fi mai de lungă durată întrucât sunt mai multe
echipe implicate, însă având în vedere sistemele cloud, scalarea verticală se face foarte rapid
și nu necesită configurări adiționale. Însă acest tip de scalare nu este o soluție ce va
funcționa la nesfârșit, se observă că legea lui Moore nu se mai aplică, astfel îmbunătățirile
tehnologice nu sunt la fel de drastice în fiecare an. Nu ar trebui să ne bazăm că putem
schimba mașina de calcul, mai ales că folosirea tehnologiilor foarte puternice ar deveni
costisitor. În acest scop, putem folosi algoritmi mai eficienți sau alte tipuri de scalare.

Scalarea orizontală se referă la multiplicarea instanțelor ale unui serviciu, în acest
stil putem crește numărul de procesări ce se pot face în același timp. Implementarea
cea mai simplă se poate face folosind un balansator de încărcătură (load balancer) ce va
dirija traficul asigurând că traficul este egal pe fiecare dintre microservicii. Acest lucru
este posibil atunci când putem să distribuim o acțiune către mai multe locuri,
însă putem avea situația în care distribuim sarcinile din interiorul unei cereri,
astfel o altă implementare ar fi separarea unor cerințe din interiorul unei cereri
către mai multe microservicii ce au unic, de procesare, iar scalarea s-ar face asupra acestora.
Am mai menționat și scalarea bazei de date prin folosirea de replici de citire ce sunt sincornizate
cu baza de date destinată scrierilor. Limitările acestui tip de scalare se rezumă la dificultățile de
implementare, astfel putem întâmpina mai multe probleme de rețelistică sau de sincronizare a datelor
sau chiar recrearea unui nou mod de desfășurare destinat acestui stil distribuit de lucru.

Partiționarea datelor se referă la distribuirea cererilor către un anumit set de microservicii
în funcție de natura cererii. Astfel, putem avea microservicii de același fel, cu funcționalitate
identică însă care se ocupă de date diferite. Aceasta poate să fie o îmbunătățire întrucât
am avea sisteme de procesare dedicate unor anumite cereri, astfel dacă am întâlnii mai mult
trafic într-un anumit loc, am putea planifica o partiționare din nou, iar dacă nu avem
atunci să regrupăm anumite date. Implementarea se poate face în funcție de tehnologie, astfel,
dacă baza de date pe care noi o folosim oferă asistență în acest loc (de exemplu Cassandra)
atunci putem să o facem la nivelul acesteia, sau să implementăm servicii de proxy ce redirecționează
traficul către microserviciile ce ne oferă funcționalitatea de care avem nevoie. Acest tip
de scalare este eficient când avem suntem constrânși din punct de vedere al scrierilor,
întrucât acestea nu pot fi eficient distribuite în alt mod. Limitările pot fi
faptul că nu se aduce o îmbunătățire la fel de mare și în funcție de modul în care ne facem
grupările ne poate duce să avem un grup de persoane afectat, astfel putem grupa
acest tip de scalare cu cele precedente pentru efectivitate mai bună. În același stil,
stabilirea modului de grupare și dimensiunile partițiilor pot fi dificil de stabilit.

Majoritatea formelor de scalare încercau să nu modifice structura aplicației prea mult,
însă după ce epuizăm aceste forme, putem încerca extinderea aplicației prin decuplarea
funcționalității în alte microsisteme. Beneficiul acestui tip ar fi posibila eficientizare
a procesului întrucât s-ar putea parta încărcătura însă ar crește complexitatea sistemului
și poate cauza degradări ale perfomanței întrucât s-ar introduce o cerere pe rețea nouă,
astfel trebuie să ne asigurăm că implementarea acestui tip de funcționalitate ar avea
sens.

Sunt multe cazuri în care soluțiile pe care le creăm sunt mult mai complicate decât ceea ce
ne cere sistemul. Toate implementările de scalare sunt incluse în această frază, astfel
nu ar trebui să adăugam complixate fără să fie dovedit că am avea nevoie. În general,
există multe caracteristici introduse de dezvoltatori însă care nu sunt folosite mai niciodată
de către utilizator, însă atunci când aceste funcționalități au șansa să strice aplicația
ar trebui să fie evitate și aplicate doar la nevoie. Iar în acest context, întrucât microserviciile
ne oferă o flexibilitate ridicată putem să aplicăm la un anumit nivel toate tipurile de scalare
în loc să alegem doar una din ele.

Există și conceptul de auto scalare, în general ne putem gândii ca sistemul să fie mai puternic
accesat într-un anumit interval, astfel putem să creștem instasnțele de microservicii
în această perioadă. Ofertanții de infrastructură cloud ne oferă diferite metode
de autoscalare deja în platformă și sub diferite forme, de exemplu atunci când ajungem
la un anumită încărcătură pe un anumit nod pe o anumită perioadă putem să mai creăm o
instanță automat. Astfel autoscalarea poate fi reactivă sau predictivă, ambele aducând
îmbunătățiri însă trebuie să analizăm datele, ce poate fi făcut cu algoritmi complecși
precum cei de Inteligența Artificială / ML.

\subsection{Caching}

Caching este o metodă de a salva informația cerută la un moment dat de către un utilizator
și prevenirea recalculării modului de a ajunge la date și doar servirea aceluiași răspuns.
Atunci când putem să oferim același răspund întrucât l-am salvat putem spune că avem
un „cache hit” și când nu, un „cache miss”

Există multe motive pentru care am adopta această tactică, întrucât sistemul de cachare
are ca rost prevenirea recalculărilor inutile, putem îmbunătății performanța sistemului
întrucât unele dintre aceste calcule pot include cereri pe Internet ce adaugă latență.
În același stil putem eficientiza traficul dacă avem cachate anumite răspunsuri
pe care doar le livrăm de mai multe ori, astfel întrucât nu aduc complexitate pot fi
scalate cu ușurință. Deși ar scădea consistența, existența unui sistem de cache ne-ar putea
permite să rulăm o anumită perioadă de timp fără ca sursa obținerii datelor să fie disponibilă,
în acest stil putem ascunde problemele de puțină durată întrucât avem deja o sursă de date
introdusă.

Această tehnică poate fi aplicată la mai multe nivele, la nivelul clientului, putem salva
în interfață datele, de exemplu pe telefoane mobile putem face o dată o cerere către baza
de date, salvăm rezultatul și acesta va fi disponibil chiar și atunci când nu avem Internet,
acest lucru este vizibil în rețelele de socializare care atunci când deschidem aplicația
mereu au anumite postări preîncărcate, această interacțiune ne permite să salvăm baterie
și să nu creăm prea multe cereri, în același stil conținutul pe care îl afișăm utilizatorului
este mai greu de controlat și poate diferi de la unul la altul. Cacharea la nivel de server
ne permite să evităm anumite operațiunii de lungă durată pe care ne așteptăm să nu se întâmple
foarte des, astfel putem să trimitem un răspuns salvat. Această operațiune ne permite să
avem un control mai mare asupra datelor pe care le salvăm, însă clientul tot ar trebui să consume
resurse făcând cererea. În acest stil putem să salvăm informații ale unei cereri specifice,
iar dacă aceasta este repetată atunci se va trimite răspunsul vechi.

Atunci când vorbim despre salvarea unei informații prin caching, trebuie să luam în
vedere modul în care ștergem această salvare. Dacă nu am luat asta în considerare atunci clientul
ar vedea informații destul de vechi ce nu ar fi actualizate. Cel mai simplu mod de implementare
este specificarea unui timp la care informația din cache expiră. Intervalul poate fi dificil
de ales iar în același timp pot exista cazuri în care datele se actualizează fix după ce
clientul le înregistrează ca find cele mai recente iar în cazul în care TTL (Time To Live) este
setat mare ar putea cauza probleme. În același fel putem eticheta fiecare cerere cu un ID,
iar dacă ID-ul nu se schimbă atunci putem trimite un răspuns mult mai mic. Dacă avem o resursă
ce este disponibilă la un anumit URI, dacă am face cerere pentru aceași resursă putem trimite
un identificator al datelor pe care le avem iar server-ul ne poate trimite fie date noi,
fie faptul că datele nu s-au schimbat. O altă metodă de invalidare a cache-ului poate
fi folosirea de notificări, astfel server-ul va trimite fiecărui client care a cache-uit
un anumit mesaj, fie cu date noi fie doar faptul că au fost invalidate. Aceasta implementare
ar aduce avantajul că nu ar exista date vechi pentru clienți însă implementarea unui astfel
de mecanism este complexă și poate consumă destul de multe resurse. De asemenea, cache-ul
poate fi modificat fix după ce resursa se schimbă, o astfel de abordare ar avea sens
dacă am face cache-ing pe un server, sau să îl folosim ca un buffer în care scriem mai întâi
în cache și după acesta se va sincroniza cu serverul.

Caching-ul este o metodă de optimizare a traficului, astfel ar trebui să fie folosit
doar acolo unde am considera că ar crea o îmbunătățire a sistemului, la fel ca la scalare
acesta poate fi introdus treptat, deși poate face parte încă din arhitectura originală
însă putem să învestim resurse în ceva în care nu ar fi necesar și am aduce complexitate
într-un loc în care poate nu e nevoie.
